{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Using LangGraph\n",
    "In this section we will see how we can build a simple chain using Langgraph that uses 4 important concepts\n",
    "\n",
    "- How to use chat messages as our graph state\n",
    "- How to use chat models in graph nodes\n",
    "- How to bind tools to our LLM in chat models\n",
    "- How to execute the tools call in our graph nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use chat messages as our graph state\n",
    "##### Messages\n",
    "\n",
    "We can use messages which can be used to capture different roles within a conversation.\n",
    "LangChain has various message types including HumanMessage, AIMessage, SystemMessage and ToolMessage.\n",
    "These represent a message from the user, from chat model, for the chat model to instruct behavior, and from a tool call.\n",
    "\n",
    "Every message have these important components.\n",
    "\n",
    "- content - content of the message\n",
    "- name - Specify the name of author\n",
    "- response_metadata - optionally, a dict of metadata (e.g., often populated by model provider for AIMessages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: LLMModel\n",
      "\n",
      "Please tell me how can I help\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Sushant\n",
      "\n",
      "I want to learn coding\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: LLMModel\n",
      "\n",
      "Which programming language you want to learn\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Sushant\n",
      "\n",
      "I want to learn python programming language\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "from pprint import pprint\n",
    "\n",
    "messages=[AIMessage(content=f\"Please tell me how can I help\",name=\"LLMModel\")]\n",
    "messages.append(HumanMessage(content=f\"I want to learn coding\",name=\"Sushant\"))\n",
    "messages.append(AIMessage(content=f\"Which programming language you want to learn\",name=\"LLMModel\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn python programming language\",name=\"Sushant\"))\n",
    "\n",
    "for message in messages:\n",
    "    message.pretty_print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Models\n",
    "\n",
    "We can use the sequence of message as input with the chatmodels using LLM's and OPENAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vanilla\\anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"openai/gpt-oss-120b\")\n",
    "result=llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 2910,\n",
       "  'prompt_tokens': 113,\n",
       "  'total_tokens': 3023,\n",
       "  'completion_time': 6.32841501,\n",
       "  'prompt_time': 0.008546347,\n",
       "  'queue_time': 0.078570772,\n",
       "  'total_time': 6.336961357,\n",
       "  'completion_tokens_details': {'reasoning_tokens': 33}},\n",
       " 'model_name': 'openai/gpt-oss-120b',\n",
       " 'system_fingerprint': 'fp_e88ce9c728',\n",
       " 'service_tier': 'on_demand',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None,\n",
       " 'model_provider': 'groq'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools\n",
    "Tools can be integrated with the LLM models to interact with external systems. External systems can be API's, third party tools.\n",
    "\n",
    "Whenever a query is asked the model can choose to call the tool and this query is based on the \n",
    "natural language input and this will return an output that matches the tool's schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a:int,b:int)-> int:\n",
    "    \"\"\" Add a and b\n",
    "    Args:\n",
    "        a (int): first int\n",
    "        b (int): second int\n",
    "\n",
    "    Returns:\n",
    "        int\n",
    "    \"\"\"\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000015173C36B30>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000015174D45870>, model_name='openai/gpt-oss-120b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Binding tool with llm\n",
    "\n",
    "llm_with_tools=llm.bind_tools([add])\n",
    "\n",
    "tool_call=llm_with_tools.invoke([HumanMessage(content=f\"Calculate the precise sum of 15.75 and 32.89 using the available mathematical tools\",name=\"Sushant\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using messages as state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class State(TypedDict):\n",
    "    message:list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducers\n",
    "Now, we have a minor problem!\n",
    "\n",
    "As we discussed, each node will return a new value for our state key messages.\n",
    "\n",
    "But, this new value will override the prior messages value.\n",
    "\n",
    "As our graph runs, we want to append messages to our messages state key.\n",
    "\n",
    "We can use reducer functions to address this.\n",
    "\n",
    "Reducers allow us to specify how state updates are performed.\n",
    "\n",
    "If no reducer function is specified, then it is assumed that updates to the key should override it as we saw before.\n",
    "\n",
    "But, to append messages, we can use the pre-built add_messages reducer.\n",
    "\n",
    "This ensures that any messages are appended to the existing list of messages.\n",
    "\n",
    "We simply need to annotate our messages key with the add_messages reducer function as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "class State(TypedDict):\n",
    "    messages:Annotated[list[AnyMessage],add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducers with add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Please tell me how can I help', additional_kwargs={}, response_metadata={}, name='LLMModel'),\n",
       " HumanMessage(content='I want to learn coding', additional_kwargs={}, response_metadata={}, name='Sushant')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_messages=[AIMessage(content=f\"Please tell me how can I help\",name=\"LLMModel\")]\n",
    "initial_messages.append(HumanMessage(content=f\"I want to learn coding\",name=\"Sushant\"))\n",
    "initial_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Which programming language you want to learn', additional_kwargs={}, response_metadata={}, name='LLMModel')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message=AIMessage(content=f\"Which programming language you want to learn\",name=\"LLMModel\")\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Please tell me how can I help', additional_kwargs={}, response_metadata={}, name='LLMModel', id='98e7e024-a1d6-4655-8239-f7bd3e807630'),\n",
       " HumanMessage(content='I want to learn coding', additional_kwargs={}, response_metadata={}, name='Sushant', id='ce7969fd-3c6d-427c-b6a3-1216dd2ce4c7'),\n",
       " AIMessage(content='Which programming language you want to learn', additional_kwargs={}, response_metadata={}, name='LLMModel', id='87c441bc-2173-4180-9d8e-e0ba29480468')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Reducers add_messages is to append instead of override\n",
    "add_messages(initial_messages,ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## chatbot node functionality\n",
    "def llm_tool(state:State):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "builder=StateGraph(State)\n",
    "\n",
    "builder.add_node(\"llm_tool\",llm_tool)\n",
    "\n",
    "builder.add_edge(START,\"llm_tool\")\n",
    "builder.add_edge(\"llm_tool\",END)\n",
    "\n",
    "graph=builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Calculate the precise sum of 15.75 and 32.89\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The precise sum of 15.75 + 32.89 is **48.64**.\n"
     ]
    }
   ],
   "source": [
    "## invocation\n",
    "\n",
    "messages=graph.invoke({\"messages\":\"Calculate the precise sum of 15.75 and 32.89\"})\n",
    "\n",
    "for message in messages[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "\n",
    "builder=StateGraph(State)\n",
    "\n",
    "## Add nodes\n",
    "\n",
    "builder.add_node(\"llm_tool\",llm_tool)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## Add Edge\n",
    "builder.add_edge(START,\"llm_tool\")\n",
    "builder.add_conditional_edges(\n",
    "    \"llm_tool\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge(\"tools\",END)\n",
    "\n",
    "\n",
    "graph_builder = builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## invocation\n",
    "\n",
    "messages=graph.invoke({\"messages\":\"What 756.23423 plus 2342.123 using available tools\"})\n",
    "\n",
    "for message in messages[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=graph.invoke({\"messages\":\"What Machine Learning\"})\n",
    "\n",
    "for message in messages[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
